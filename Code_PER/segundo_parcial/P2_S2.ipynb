{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8GCctR7n-FD"
   },
   "source": [
    "# Ensembles de árboles en un dataset de detección de spam\n",
    "\n",
    "Si bien en anteriores prácticas hemos insistido en emplear los datasets de digits y faces, es bien conocido que para este tipo de datasets que representan imágenes, no es lo habitual emplear árboles de decisión.\n",
    "\n",
    "Árboles de decisión y todos los ensembles propuestos funcionan en la práctica muy bien en datos tabulares como puede ser el problema de reconocimiento de spam en mails.\n",
    "\n",
    "Se propone pues emplear el dataset id=44 de openml de detección de Spam. Son un total de 4601 muestras con 57 características.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nYzcASaoyGi"
   },
   "source": [
    "## Un primer clasificador con un único árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "44-gXIlqnmWp",
    "ExecuteTime": {
     "end_time": "2024-05-25T18:33:06.820003400Z",
     "start_time": "2024-05-25T18:33:02.134639100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 57)\n",
      "Precisión: 93.9% con {'max_depth': 10, 'min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from warnings import filterwarnings\n",
    "\n",
    "## Descarga del dataset Spam\n",
    "filterwarnings('ignore')\n",
    "X, y = fetch_openml(data_id=44, as_frame=False, cache=True, return_X_y=True)\n",
    "print(X.shape)\n",
    "\n",
    "## Partición train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)\n",
    "\n",
    "\n",
    "## Grid Search\n",
    "G = {\"max_depth\": [2,4,6,8,10], \"min_samples_split\": [2,3,4]}\n",
    "\n",
    "GS = GridSearchCV(DecisionTreeClassifier(random_state=23), G, scoring='accuracy', refit=True, cv=5)\n",
    "\n",
    "acc = GS.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f'Precisión: {acc:.1%} con {GS.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WQrVPtw5Atg"
   },
   "source": [
    "## Bagging\n",
    "\n",
    "Bagging es una técnica genérica de muestreo con remplanzamiento del conjunto de muestras de entrenamiento. Se puede emplear junto con cualquier clasificador para obtener un ensemble. Los parámetros más importantes son por un lado el estimador que se quiere emplear, en nuestro caso un DecisionTree, y el número de estimadores que se quiere combinar en el ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uLU5GpLe5DBY",
    "ExecuteTime": {
     "end_time": "2024-05-25T17:30:43.460464300Z",
     "start_time": "2024-05-25T17:30:42.197659500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 94.7%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "clf= BaggingClassifier(estimator=DecisionTreeClassifier(random_state=23,max_depth=10,min_samples_split=4),n_estimators=10)\n",
    "\n",
    "acc = clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f'Precisión: {acc:.1%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0m7gcY1M57Np"
   },
   "source": [
    "**Ejercicio:** Encuentra los mejores parámetros mediante grid search. En concreto, n_estimators y max_depth de los árboles de decisión empleados. Se debería poder llegar alrededor de un **94.5% de acierto**.  "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 94.5% con {'estimator__max_depth': 50, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "G = {\"n_estimators\": [2, 5, 10, 20, 50], \"estimator__max_depth\": [2, 5, 10, 20, 50]}\n",
    "\n",
    "GS = GridSearchCV(clf, G, scoring='accuracy', refit=True, cv=5)\n",
    "acc = GS.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f'Precisión: {acc:.1%} con {GS.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T17:43:30.746878800Z",
     "start_time": "2024-05-25T17:41:26.633509800Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qX423LvPxr7Q"
   },
   "source": [
    "## RandomForest\n",
    "\n",
    "RandomForest es otra técnica de ensemble, en este caso no genérica sino particular para árboles de decisión. Cada árbol se construye empleando una selección aleatoria de las características en cada uno de los nodos. El parámetro más importante es \"n_estimators\", el número de árboles que combino. El parámetro binario \"bootstrap\" controla también si se realiza bootstrap de las muestras (Bagging) o no.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a2zKM2o1ye2S",
    "ExecuteTime": {
     "end_time": "2024-05-25T18:34:18.722730100Z",
     "start_time": "2024-05-25T18:34:18.586350100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 94.1%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf= RandomForestClassifier(n_estimators=10, max_depth=10, min_samples_split=4, bootstrap=False, random_state=23)\n",
    "\n",
    "acc = clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f'Precisión: {acc:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5u58QclQz27K"
   },
   "source": [
    "**Ejercicio:** Realiza una búsqueda de parámetros mediande grid search. En concreto para los parámetros: n_estimators, max_depth y bootstrap. Se debería poder llegar alrededor de un **95% de acierto**.  "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 94.7% con {'bootstrap': False, 'max_depth': 20, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "G = {\"n_estimators\": [2, 5, 10, 20, 50], \"bootstrap\": [True, False], \"max_depth\": [2, 5, 10, 15, 20]}\n",
    "\n",
    "GS = GridSearchCV(clf, G, scoring='accuracy', refit=True, cv=5)\n",
    "acc = GS.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f'Precisión: {acc:.1%} con {GS.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T18:37:59.471879100Z",
     "start_time": "2024-05-25T18:37:27.543373400Z"
    }
   },
   "execution_count": 4
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
