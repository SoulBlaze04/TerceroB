{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percepción (PER): examen de prácticas del bloque 1, grupo 3CO11, turno 2, 23-4-2024, 8:45-9:30\n",
    "\n",
    "Lee este cuaderno y realiza las actividades y ejercicios propuestos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías relevantes\n",
    "\n",
    "Ejecuta el código siguiente para importar librerías relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T06:54:41.984939800Z",
     "start_time": "2024-04-23T06:54:41.980321500Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura y partición del corpus default-of-credit-card-clients\n",
    "\n",
    "Ejecuta el código siguiente con random_state igual a las tres últimas cifras de tu DNI/NIE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 13272  D = 21  C = 2  N_train = 11944  N_test = 1328\n"
     ]
    }
   ],
   "source": [
    "X, y = fetch_openml(\"default-of-credit-card-clients\", version=4, return_X_y=True, as_frame=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=123)\n",
    "N, D = X.shape; C = len(np.unique(y)); N_train = len(X_train); N_test = len(X_test)\n",
    "print(f'N = {N}  D = {D}  C = {C}  N_train = {N_train}  N_test = {N_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea del [**tabular data learning benchmark**](https://arxiv.org/abs/2207.08815). Se trata de predecir si se va a producir impago o no (2 clases) con tarjetas de crédito a partir del crédito dado e información (financiera) del cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento de referencia con LDA\n",
    "\n",
    "Ejecuta el código siguiente para estudiar el error de LDA con ajuste de hiper-parámetros mediante GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 33.3% con {'lda__tol': 1e-05, 'pca__n_components': 0.99}\n",
      "5.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "scaler = StandardScaler(); pca = PCA(); lda = LinearDiscriminantAnalysis()\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"lda\", lda)])\n",
    "G = {\"pca__n_components\": [.9, .99, None],\n",
    "     \"lda__tol\": [1e-5, 1e-4, 1e-3]}\n",
    "GS = GridSearchCV(pipe, G, scoring='accuracy', refit=True, cv=5)\n",
    "err = 1.0 - GS.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f'Error: {err:.1%} con {GS.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Replica el código del experimento de referencia y modifícalo para estudiar el error de QDA con ajuste de hiper-parámetros mediante GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 32.7% con {'pca__n_components': 0.99, 'qda__reg_param': 1}\n",
      "2.34 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "scaler = StandardScaler(); pca = PCA(); qda = QuadraticDiscriminantAnalysis()\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"qda\", qda)])\n",
    "G = {\"pca__n_components\": [.9, .99, None],\n",
    "     \"qda__reg_param\": [1e-2, .1, .5, .9, 1]}\n",
    "GS = GridSearchCV(pipe, G, scoring='accuracy', refit=True, cv=5)\n",
    "err = 1.0 - GS.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f'Error: {err:.1%} con {GS.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T07:03:25.343161300Z",
     "start_time": "2024-04-23T07:03:23.002420400Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "El error usando los mejores parámetros con QDA es menor que usando los mejores parámetros con LDA\n",
    "Por lo tanto, sería mejor utilizar este modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Replica el código del experimento de referencia y modifícalo para estudiar el error de regresión logística con ajuste de hiper-parámetros mediante GridSearchCV. Incluye la posibilidad de preprocesar la entrada con características polinómicas seguida de estandarización y PCA."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 30.1% con {'logreg__C': 0.1, 'logreg__solver': 'liblinear', 'logreg__tol': 1e-05, 'pca__n_components': 0.99}\n",
      "9.57 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "scaler = StandardScaler(); pca = PCA(); logreg = LogisticRegression()\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"logreg\", logreg)])\n",
    "G = {\"pca__n_components\": [.9, .99, None],\n",
    "     \"logreg__solver\": [\"lbfgs\", \"liblinear\"],\n",
    "     \"logreg__tol\": [1e-5, 1e-4, 1e-3],\n",
    "     \"logreg__C\": [.1, 1, 10]}\n",
    "GS = GridSearchCV(pipe, G, scoring='accuracy', refit=True, cv=5)\n",
    "err = 1.0 - GS.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f'Error: {err:.1%} con {GS.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T07:09:16.542921200Z",
     "start_time": "2024-04-23T07:09:06.966424500Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "El error usando regresión logística con los mejores parámetros es menor que LDA y que QDA, por lo tanto es un modelo más preciso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora comprobaremos si utilizar características polinómicas mejora la solución (la primera celda es equivalente al ejercicio anterior porque poly__degree = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 30.1% con {'logreg__C': 0.1, 'logreg__solver': 'liblinear', 'logreg__tol': 1e-05, 'pca__n_components': 0.99, 'poly__degree': 1}\n",
      "10.5 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "scaler = StandardScaler(); pca = PCA(); logreg = LogisticRegression(); poly = PolynomialFeatures()\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"poly\", poly), (\"pca\", pca), (\"logreg\", logreg)])\n",
    "G = {\"pca__n_components\": [.9, .99, None],\n",
    "     \"poly__degree\": [1],\n",
    "     \"logreg__solver\": [\"lbfgs\", \"liblinear\"],\n",
    "     \"logreg__tol\": [1e-5, 1e-4, 1e-3],\n",
    "     \"logreg__C\": [.1, 1, 10]}\n",
    "GS = GridSearchCV(pipe, G, scoring='accuracy', refit=True, cv=5)\n",
    "err = 1.0 - GS.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f'Error: {err:.1%} con {GS.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T07:16:05.743444300Z",
     "start_time": "2024-04-23T07:15:55.217795200Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 28.7% con {'logreg__C': 0.1, 'logreg__solver': 'lbfgs', 'logreg__tol': 1e-05, 'pca__n_components': None, 'poly__degree': 2}\n",
      "4min 1s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "scaler = StandardScaler(); pca = PCA(); logreg = LogisticRegression(); poly = PolynomialFeatures()\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"poly\", poly), (\"pca\", pca), (\"logreg\", logreg)])\n",
    "G = {\"pca__n_components\": [.9, .99, None],\n",
    "     \"poly__degree\": [2],\n",
    "     \"logreg__solver\": [\"lbfgs\", \"liblinear\"],\n",
    "     \"logreg__tol\": [1e-5, 1e-4, 1e-3],\n",
    "     \"logreg__C\": [.1, 1, 10]}\n",
    "GS = GridSearchCV(pipe, G, scoring='accuracy', refit=True, cv=5)\n",
    "err = 1.0 - GS.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f'Error: {err:.1%} con {GS.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T07:20:21.455188700Z",
     "start_time": "2024-04-23T07:16:19.918940400Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "El resultado con características cuadráticas es mejor que con lineales"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Probaremos ahora con cúbicas pero solo con una pequeña porción de los datos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 41.4% con {'logreg__C': 0.1, 'logreg__solver': 'lbfgs', 'logreg__tol': 1e-05, 'pca__n_components': 0.9, 'poly__degree': 3}\n",
      "12.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "scaler = StandardScaler(); pca = PCA(); logreg = LogisticRegression(); poly = PolynomialFeatures()\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"poly\", poly), (\"pca\", pca), (\"logreg\", logreg)])\n",
    "G = {\"pca__n_components\": [.9, .99, None],\n",
    "     \"poly__degree\": [3],\n",
    "     \"logreg__solver\": [\"lbfgs\", \"liblinear\"],\n",
    "     \"logreg__tol\": [1e-5, 1e-4, 1e-3],\n",
    "     \"logreg__C\": [.1, 1, 10]}\n",
    "GS = GridSearchCV(pipe, G, scoring='accuracy', refit=True, cv=5)\n",
    "err = 1.0 - GS.fit(X_train[:100, :], y_train[:100]).score(X_test, y_test)\n",
    "print(f'Error: {err:.1%} con {GS.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T07:22:27.616464800Z",
     "start_time": "2024-04-23T07:22:15.530443500Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "El error a priori es mayor, y por lo tanto el ajuste peor. Probaremos con más datos para comprobar el ajuste"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 36.7% con {'logreg__C': 0.1, 'logreg__solver': 'liblinear', 'logreg__tol': 1e-05, 'pca__n_components': None, 'poly__degree': 3}\n",
      "1min 37s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "scaler = StandardScaler(); pca = PCA(); logreg = LogisticRegression(); poly = PolynomialFeatures()\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"poly\", poly), (\"pca\", pca), (\"logreg\", logreg)])\n",
    "G = {\"pca__n_components\": [.9, .99, None],\n",
    "     \"poly__degree\": [3],\n",
    "     \"logreg__solver\": [\"lbfgs\", \"liblinear\"],\n",
    "     \"logreg__tol\": [1e-5, 1e-4, 1e-3],\n",
    "     \"logreg__C\": [.1, 1, 10]}\n",
    "GS = GridSearchCV(pipe, G, scoring='accuracy', refit=True, cv=5)\n",
    "err = 1.0 - GS.fit(X_train[:500, :], y_train[:500]).score(X_test, y_test)\n",
    "print(f'Error: {err:.1%} con {GS.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T07:24:50.866506500Z",
     "start_time": "2024-04-23T07:23:13.720213100Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "El error mejora al usar más datos, así que sería recomendable utilizar porciones mayores de los datos en caso de que el tiempo que consuma sea factible"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
